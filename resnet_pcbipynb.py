# -*- coding: utf-8 -*-
"""Resnet_pcbipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1IeqJXQ7VRGLkbJ6cYYkPY7oDQV4cSc8w
"""

from google.colab import drive
import os
import zipfile


drive.mount('/content/drive')



zip_path = '/content/drive/MyDrive/pcb-defect-dataset.zip'


print("Dosyalar Ã§Ä±karÄ±lÄ±yor, lÃ¼tfen bekle...")
with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    zip_ref.extractall('/content/')

print(" Zip Ã§Ä±karma iÅŸlemi tamamlandÄ±!")

import os
import cv2
import shutil


base_dataset_path = "/content/pcb-defect-dataset"
output_dataset_path = "/content/resnet_data"

# class'lar
classes = [
    "mouse_bite",       # 0
    "spur",             # 1
    "missing_hole",     # 2
    "short",            # 3
    "open_circuit",     # 4
    "spurious_copper"   # 5
]
# ---------------

def process_data(split_type):
    print(f" {split_type.upper()} klasÃ¶rÃ¼ iÅŸleniyor...")

    img_dir = os.path.join(base_dataset_path, split_type, "images")
    lbl_dir = os.path.join(base_dataset_path, split_type, "labels")
    out_dir = os.path.join(output_dataset_path, split_type)

    if not os.path.exists(img_dir):
        print(f" KlasÃ¶r bulunamadÄ±: {img_dir}")
        return


    for cls in classes:
        os.makedirs(os.path.join(out_dir, cls), exist_ok=True)

    count = 0
    txt_files = [f for f in os.listdir(lbl_dir) if f.endswith('.txt')]

    for txt_file in txt_files:
        base_name = os.path.splitext(txt_file)[0]


        img_path = os.path.join(img_dir, base_name + ".jpg")
        if not os.path.exists(img_path):
            img_path = os.path.join(img_dir, base_name + ".png")
            if not os.path.exists(img_path): continue

        img = cv2.imread(img_path)
        if img is None: continue
        h_img, w_img = img.shape[:2]


        with open(os.path.join(lbl_dir, txt_file), 'r') as f:     # etikete eriÅŸ
            lines = f.readlines()

        for i, line in enumerate(lines):
            try:                                 # veri ayÄ±rma
                data = line.strip().split()
                cls_id = int(data[0])
                if cls_id >= len(classes): continue

                x_c, y_c, w, h = map(float, data[1:])   # kordinat al

                 # piksel hesabÄ±
                x1 = int((x_c - w/2) * w_img)
                y1 = int((y_c - h/2) * h_img)
                x2 = int((x_c + w/2) * w_img)
                y2 = int((y_c + h/2) * h_img)


                x1, y1 = max(0, x1), max(0, y1)                 # sÄ±nÄ±r dÃ¼zeltme
                x2, y2 = min(w_img, x2), min(h_img, y2)

                crop = img[y1:y2, x1:x2]              #kesme iÅŸlemi


                if crop.size == 0 or w < 0.01 or h < 0.01: continue


                save_name = f"{base_name}_crop_{i}.jpg"               #kaydet
                save_path = os.path.join(out_dir, classes[cls_id], save_name)
                cv2.imwrite(save_path, crop)
                count += 1
            except: pass

    print(f" {split_type} tamamlandÄ±: {count} resim kesildi.")


process_data("train")   # baÅŸla
process_data("val")

import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import ResNet50
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, BatchNormalization
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping


train_dir = '/content/resnet_data/train'
val_dir = '/content/resnet_data/val'

# Data Augmentation kÄ±smÄ±
train_datagen = ImageDataGenerator(
    rescale=1./255,  #0-255 olan image 0-1 arasÄ±nda Ã¶lÃ§eklendiridi
    rotation_range=10,           #dÃ¶ndÃ¼rme
    width_shift_range=0.1,       # yatay kaydÄ±rma
    height_shift_range=0.1,      # dikey kaydÄ±rma
    horizontal_flip=True,        # yatay aynalama
    vertical_flip=True,          # dikey aynalama
    fill_mode='nearest'          # boÅŸ pikselleri doldur
)

val_datagen = ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow_from_directory(
    train_dir,
    target_size=(224, 224),
    batch_size=32,
    class_mode='categorical'
)

val_generator = val_datagen.flow_from_directory(
    val_dir,
    target_size=(224, 224),
    batch_size=32,
    class_mode='categorical'
)

 # model mimarisi
base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))


base_model.trainable = True

# Ä°lk 140 katmanÄ± dondurduk Resnetin kendi bildiÄŸini bozmamak  iÃ§in
for layer in base_model.layers[:140]:
    layer.trainable = False

x = base_model.output
x = GlobalAveragePooling2D()(x)               # 3D to 2D veri sÄ±kÄ±ÅŸtÄ±rma
x = BatchNormalization()(x)                  # veri sayÄ±sal denge
x = Dense(512, activation='relu')(x)        # 512 adet norÃ¶n asÄ±l Ã¶ÄŸrenme katmanÄ±
x = Dropout(0.4)(x)                         # %40
predictions = Dense(6, activation='softmax')(x)

model = Model(inputs=base_model.input, outputs=predictions)

  # eÄŸitim sigortlarÄ±
checkpoint = ModelCheckpoint(                       # en iyi epoch
    "/content/drive/MyDrive/pcb_resnet_finetuned.h5",
    monitor='val_accuracy',
    mode='max',
    save_best_only=True,
    verbose=1
)


reduce_lr = ReduceLROnPlateau(
    monitor='val_loss',
    factor=0.2,                    # lr deÄŸeri 0.2 le Ã§arparÄ±z 5 kat dÃ¼ÅŸÃ¼ÅŸ
    patience=3,
    min_lr=1e-7,                   # hÄ±z alt limit
    verbose=1
)


early_stop = EarlyStopping(
    monitor='val_accuracy',
    patience=8,                   # Ã¶ÄŸremem yoksa 8 epoch bitir
    restore_best_weights=True
)



model.compile(optimizer=Adam(learning_rate=0.00001),    # learning rate'i Ã§ok dÃ¼ÅŸÃ¼rdÃ¼k (1e-5) hasas ayar
              loss='categorical_crossentropy',
              metrics=['accuracy'])

print("ğŸš€ Fine-Tuning BaÅŸlÄ±yor (Bu sefer olacak)...")
history = model.fit(
    train_generator,
    epochs=30,
    validation_data=val_generator,
    callbacks=[checkpoint, reduce_lr, early_stop]
)

import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns
from sklearn.metrics import classification_report, confusion_matrix
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing.image import ImageDataGenerator


acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
loss = history.history['loss']
val_loss = history.history['val_loss']
epochs_range = range(1, len(acc) + 1)

plt.figure(figsize=(16, 6))

# BaÅŸarÄ± GrafiÄŸi
plt.subplot(1, 2, 1)
plt.plot(epochs_range, acc, label='EÄŸitim BaÅŸarÄ±sÄ± (Train)')
plt.plot(epochs_range, val_acc, label='DoÄŸrulama BaÅŸarÄ±sÄ± (Validation)', color='orange', linewidth=2)
plt.title('Model BaÅŸarÄ± GrafiÄŸi (Accuracy)', fontsize=14)
plt.xlabel('Epoch')
plt.ylabel('BaÅŸarÄ± OranÄ±')
plt.legend(loc='lower right')
plt.grid(True, alpha=0.3)

# KayÄ±p GrafiÄŸi
plt.subplot(1, 2, 2)
plt.plot(epochs_range, loss, label='EÄŸitim KaybÄ± (Train)')
plt.plot(epochs_range, val_loss, label='DoÄŸrulama KaybÄ± (Validation)', color='red', linewidth=2)
plt.title('Model Hata GrafiÄŸi (Loss)', fontsize=14)
plt.xlabel('Epoch')
plt.ylabel('Hata OranÄ±')
plt.legend(loc='upper right')
plt.grid(True, alpha=0.3)
plt.show()

# KARMAÅIKLIK MATRÄ°SÄ°
print("\nğŸ† En iyi model yÃ¼kleniyor ve test ediliyor...")
# Drive'daki en yÃ¼ksek skorlu modeli Ã§ekiyoruz
model = load_model("/content/drive/MyDrive/pcb_resnet_finetuned.h5")

val_dir = '/content/resnet_data/val'
val_datagen = ImageDataGenerator(rescale=1./255)

# Shuffle=False kritik Ã¶nemde!
val_generator = val_datagen.flow_from_directory(
    val_dir, target_size=(224, 224), batch_size=32,
    class_mode='categorical', shuffle=False
)

# Tahmin
Y_pred = model.predict(val_generator, verbose=1)
y_pred = np.argmax(Y_pred, axis=1)
y_true = val_generator.classes
class_names = list(val_generator.class_indices.keys())

# Matris Ã‡izimi
cm = confusion_matrix(y_true, y_pred)
plt.figure(figsize=(10, 8))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=class_names, yticklabels=class_names)
plt.title(f'Confusion Matrix (DoÄŸrulama BaÅŸarÄ±sÄ±: %{100*np.max(val_acc):.2f})', fontsize=15)
plt.ylabel('GerÃ§ek SÄ±nÄ±f')
plt.xlabel('Tahmin Edilen SÄ±nÄ±f')
plt.show()

# Rapor
print("\n--- DETAYLI SINIFLANDIRMA RAPORU ---")
print(classification_report(y_true, y_pred, target_names=class_names))